{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de9ae5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "title: \"SVM by Hand\"\n",
    "\n",
    "description: \"A gritty battle in linear algebra to implement kernel and multiclass functionality for an SVM by hand.\"\n",
    "\n",
    "author:\n",
    "  - name: Sam Herold\n",
    "  \n",
    "    url: https://samhero16.github.io/\n",
    "    \n",
    "    orcid: 0000-0002-5300-3075\n",
    "\n",
    "\n",
    "priority: 2\n",
    "\n",
    "image: 1_Lsun5-t67owndP0iTV9DNQ.png\n",
    "\n",
    "draft: false \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2217c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Warning: This notebook is extremely dense, difficult to follow, and arranged poorly - but I am proud of it so I decided to post it. I will be rearranging it for better readability soon\n",
    "\n",
    "An SVM out of the box can only separate linearly and only supports binary classification. This can be relieved with kernels and with the OneVsAll strategy. I implemented this functionality by hand on top of raw SVM code, then compared my implementation to the sklearn equivalent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee79eeb",
   "metadata": {},
   "source": [
    "# Dependencies and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a285fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import polynomial_kernel, linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda30c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       336 non-null    object \n",
      " 1   1       336 non-null    float64\n",
      " 2   2       336 non-null    float64\n",
      " 3   3       336 non-null    float64\n",
      " 4   4       336 non-null    float64\n",
      " 5   5       336 non-null    float64\n",
      " 6   6       336 non-null    float64\n",
      " 7   7       336 non-null    float64\n",
      " 8   8       336 non-null    object \n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 23.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_fwf('ecoli/ecoli.data', header = None, ) \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2121ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break into features and labels\n",
    "x = data.iloc[:,1:-1].to_numpy()\n",
    "y = data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b8864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode all of the 'cp', 'imL', etc. stuff into numbers for classification\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaf436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([  2,   2, 143,  77,   5,  35,  20,  52]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'L', 1: 'S', 2: 'cp', 3: 'im', 4: 'mL', 5: 'mU', 6: 'om', 7: 'pp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mappings and value counts\n",
    "print(np.unique(y, return_counts=True))\n",
    "dic = dict(zip( le.transform(le.classes_), le.classes_))\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be95efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f0c3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((336, 7), (336,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbf503",
   "metadata": {},
   "source": [
    "# Functions\n",
    "We will be changing the x_train and x_test data-sets later, so they are variables in the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a730b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break dataset for OneVall. 'All' is -1, 'One' is 1\n",
    "def breakDataSet(y_train, oneClass):\n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    y_train_copy[y_train != oneClass] = -1\n",
    "    y_train_copy[y_train == oneClass] = 1\n",
    "    \n",
    "    return y_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea93d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the svm weights and biases\n",
    "def getSVMs(x_train, y_train): \n",
    "    \n",
    "    \n",
    "    #make a flexible dataframe to store the wieghts and biases depending on the input shape. first column for \n",
    "    #storing index, everything else execpt lass for weights per feature, last one for bias\n",
    "    n_columns = x_train.shape[1] + 1\n",
    "    column_names = [f'Weight_{i}' for i in range(n_columns)]\n",
    "    df = pd.DataFrame(0, index=range(8), columns=column_names)\n",
    "    df = df.rename(columns={column_names[-1]: 'Bias'})\n",
    "\n",
    "\n",
    "    #print(df)\n",
    "    \n",
    "    #loop through all 8 classes and make a OneVall for each\n",
    "\n",
    "    for c in range(len(np.unique(y))):\n",
    "        \n",
    "\n",
    "        ydual_train  = breakDataSet(y_train.copy(), oneClass = c)\n",
    "        xdual_train = x_train.copy()\n",
    "\n",
    "        N = len(ydual_train)\n",
    "        XPY = xdual_train.copy()\n",
    "        for i in range(N):\n",
    "            if ydual_train[i]==-1:\n",
    "                XPY[i,:] =-1 * xdual_train[i,:]  \n",
    "                \n",
    "           \n",
    "        A = np.matmul(XPY,XPY.transpose())\n",
    "\n",
    "        AT = A.copy().transpose()\n",
    "\n",
    "        YM = np.outer(ydual_train[1:],ydual_train[1:])\n",
    "        AY = np.outer(A[0,1:],ydual_train[1:])\n",
    "        YA = np.outer(ydual_train[1:],A[0,1:])\n",
    "\n",
    "\n",
    "        Y0S = ydual_train[0]**2\n",
    "        M = AT[1:,1:] + A[0,0]*YM/Y0S - AY/ydual_train[0] - YA/ydual_train[0]\n",
    "\n",
    "\n",
    "        b = np.zeros(N-1)\n",
    "        b = 1 - ydual_train[1:]/ydual_train[0]\n",
    "\n",
    "\n",
    "        aw = np.zeros(N)\n",
    "        for i in range(2,N):\n",
    "            aw[i] = (1-ydual_train[i]/ydual_train[0])/(A[i,i] + A[0,0]*ydual_train[i]**2/ydual_train[0]**2 \n",
    "                                                   - 2*A[0,i]*ydual_train[i]/ydual_train[0])\n",
    "\n",
    "        aw[0] = -sum(ydual_train[1:]*aw[1:])/ydual_train[0]\n",
    "\n",
    "\n",
    "\n",
    "        YA   = ydual_train*aw\n",
    "\n",
    "        wght = sum(xdual_train * YA[:,None])\n",
    "        b =sum(ydual_train - np.matmul(xdual_train,wght))/N\n",
    "        \n",
    "\n",
    "       \n",
    "        df.iloc[c,0:-1] = wght\n",
    "        df.iloc[c,-1] = b\n",
    "            \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a435ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through each of the 8 classifiers and pick the class of the classifier that \n",
    "# is the most confident in the 'One' not the 'All'\n",
    "def getAccuracy(x_test, y_test, SVM):\n",
    "    testSetAcc = []\n",
    "    for j in range(x_test.shape[0]):\n",
    "        results = []\n",
    "        #loop through all 8 available SVM's\n",
    "        for i in range(8):\n",
    "            #W*features + bias\n",
    "            results.append((SVM.iloc[i,:-1].values@x_test[j]) + SVM.iloc[i,-1])\n",
    "        #pick most confident result, store true if it is the same as the actual output\n",
    "        #argmax is the most confident result. A positive number means pick the one, negative means pick the rest. \n",
    "        #so the highest positive number is the most confident 'one' result. \n",
    "        \n",
    "        testSetAcc.append(np.argmax(results) == y_test[j])\n",
    "        \n",
    "    #print(testSetAcc)\n",
    "    if len(testSetAcc) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return sum(testSetAcc)/len(testSetAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db06f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see accuracy for each specific class\n",
    "#should correspond to number of training examples\n",
    "def getAccuracyPerNumber(x_test, y_test, SVM):\n",
    "    for i in range(8):\n",
    "        #split data into only x and y of one class\n",
    "        yonlyI  = y_test[y_test == i]\n",
    "        xonlyI  = x_test[y_test == i]\n",
    "        acc = getAccuracy(xonlyI, yonlyI, SVM)\n",
    "        print(\"Accuracy for \" , i , \" or \" , dic[i] , \" : \" , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869babe",
   "metadata": {},
   "source": [
    "# MultiClass SVM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d96ffeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the train test split\n",
    "#we will be changing x_train and x_test for the kernels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size = .8,shuffle = True, random_state = 4)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0c9b4",
   "metadata": {},
   "source": [
    "### Sklearn implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76cd6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cce557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Linear SVM Accuracy: ', 0.9411764705882353)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM\n",
    "linearSVC = LinearSVC(dual=\"auto\")\n",
    "linearSVC.fit(x_train,y_train)\n",
    "y_pred = linearSVC.predict(x_test)\n",
    "\"sklean Linear SVM Accuracy: \" , accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f6b9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Linear Kernel SVM Accuracy: ', 0.8382352941176471)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Kernel SVM\n",
    "linearKernelSVC = SVC(kernel = \"linear\")\n",
    "linearKernelSVC.fit(x_train,y_train)\n",
    "y_pred = linearKernelSVC.predict(x_test)\n",
    "\"sklean Linear Kernel SVM Accuracy: \" , accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4016ea8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Polynomial SVM Accuracy: ', 0.8823529411764706)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Polynomial Kernel SVM\n",
    "polySVC = SVC(kernel = \"poly\")\n",
    "polySVC.fit(x_train,y_train)\n",
    "y_pred = polySVC.predict(x_test)\n",
    "\"sklean Polynomial SVM Accuracy: \" , accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e536d2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean RBF SVM Accuracy: ', 0.8970588235294118)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RBF Kernel SVM\n",
    "rbfSVC = SVC(kernel = \"rbf\")\n",
    "rbfSVC.fit(x_train,y_train)\n",
    "y_pred = rbfSVC.predict(x_test)\n",
    "\"sklean RBF SVM Accuracy: \" , accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d1b6e",
   "metadata": {},
   "source": [
    "### Linear (No Kernel) OneVsAll SVM\n",
    "Do not change x_train or x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced91ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.652312</td>\n",
       "      <td>-1.943609</td>\n",
       "      <td>3.244773e+00</td>\n",
       "      <td>1.531159e+00</td>\n",
       "      <td>-0.087257</td>\n",
       "      <td>0.987371</td>\n",
       "      <td>0.218332</td>\n",
       "      <td>-3.284968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.037805</td>\n",
       "      <td>-5.788647</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.392839</td>\n",
       "      <td>2.789961</td>\n",
       "      <td>-0.208726</td>\n",
       "      <td>-1.625561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-189.074352</td>\n",
       "      <td>-305.870475</td>\n",
       "      <td>-2.056133e-13</td>\n",
       "      <td>-3.610445e-13</td>\n",
       "      <td>-12.150815</td>\n",
       "      <td>-132.073554</td>\n",
       "      <td>-109.956294</td>\n",
       "      <td>379.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-47.842855</td>\n",
       "      <td>-116.962305</td>\n",
       "      <td>2.079584e+00</td>\n",
       "      <td>2.797762e-14</td>\n",
       "      <td>37.575416</td>\n",
       "      <td>107.329767</td>\n",
       "      <td>87.197460</td>\n",
       "      <td>-35.081053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.535861</td>\n",
       "      <td>-5.719501</td>\n",
       "      <td>1.089051e+01</td>\n",
       "      <td>8.881784e-16</td>\n",
       "      <td>1.658700</td>\n",
       "      <td>1.569109</td>\n",
       "      <td>-6.278016</td>\n",
       "      <td>-2.754340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.890656</td>\n",
       "      <td>-68.690367</td>\n",
       "      <td>2.519990e+00</td>\n",
       "      <td>-2.176037e-14</td>\n",
       "      <td>16.202489</td>\n",
       "      <td>56.151497</td>\n",
       "      <td>45.912457</td>\n",
       "      <td>-39.212604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.893138</td>\n",
       "      <td>-11.033733</td>\n",
       "      <td>1.243450e-14</td>\n",
       "      <td>-3.552714e-15</td>\n",
       "      <td>53.116386</td>\n",
       "      <td>-9.926145</td>\n",
       "      <td>-52.436130</td>\n",
       "      <td>4.703137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>198.907436</td>\n",
       "      <td>516.008637</td>\n",
       "      <td>-1.873485e+01</td>\n",
       "      <td>-1.531159e+00</td>\n",
       "      <td>-97.707757</td>\n",
       "      <td>-26.828006</td>\n",
       "      <td>35.550916</td>\n",
       "      <td>-307.882595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight_0    Weight_1      Weight_2      Weight_3   Weight_4    Weight_5  \\\n",
       "0    0.652312   -1.943609  3.244773e+00  1.531159e+00  -0.087257    0.987371   \n",
       "1    3.037805   -5.788647 -8.881784e-16 -8.881784e-16   1.392839    2.789961   \n",
       "2 -189.074352 -305.870475 -2.056133e-13 -3.610445e-13 -12.150815 -132.073554   \n",
       "3  -47.842855 -116.962305  2.079584e+00  2.797762e-14  37.575416  107.329767   \n",
       "4    1.535861   -5.719501  1.089051e+01  8.881784e-16   1.658700    1.569109   \n",
       "5   23.890656  -68.690367  2.519990e+00 -2.176037e-14  16.202489   56.151497   \n",
       "6    8.893138  -11.033733  1.243450e-14 -3.552714e-15  53.116386   -9.926145   \n",
       "7  198.907436  516.008637 -1.873485e+01 -1.531159e+00 -97.707757  -26.828006   \n",
       "\n",
       "     Weight_6        Bias  \n",
       "0    0.218332   -3.284968  \n",
       "1   -0.208726   -1.625561  \n",
       "2 -109.956294  379.137984  \n",
       "3   87.197460  -35.081053  \n",
       "4   -6.278016   -2.754340  \n",
       "5   45.912457  -39.212604  \n",
       "6  -52.436130    4.703137  \n",
       "7   35.550916 -307.882595  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVM = getSVMs(x_train = x_train, y_train = y_train)\n",
    "linearSVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece8fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Overall accuracy: ', 0.7647058823529411)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getAccuracy(x_test, y_test, SVM = linearSVM)\n",
    "\"Overall accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd35a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  0  or  L  :  0.0\n",
      "Accuracy for  1  or  S  :  0.0\n",
      "Accuracy for  2  or  cp  :  1.0\n",
      "Accuracy for  3  or  im  :  0.6111111111111112\n",
      "Accuracy for  4  or  mL  :  0.0\n",
      "Accuracy for  5  or  mU  :  0.0\n",
      "Accuracy for  6  or  om  :  0.0\n",
      "Accuracy for  7  or  pp  :  1.0\n"
     ]
    }
   ],
   "source": [
    "getAccuracyPerNumber(x_test, y_test, SVM = linearSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "897c7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Value Counts:  (array([0, 1, 2, 3, 4, 5, 6, 7]), array([  2,   2, 143,  77,   5,  35,  20,  52]))\n",
      "Train Value Counts:  (array([0, 1, 2, 3, 4, 5, 6, 7]), array([  2,   2, 109,  59,   5,  29,  17,  45]))\n",
      "Test Value Counts:  (array([2, 3, 5, 6, 7]), array([34, 18,  6,  3,  7]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Value Counts: \" , np.unique(y, return_counts=True))\n",
    "print(\"Train Value Counts: \" , np.unique(y_train, return_counts=True))\n",
    "print(\"Test Value Counts: \" , np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bebea",
   "metadata": {},
   "source": [
    "### Linear Kernel OneVsAll SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3abc2",
   "metadata": {},
   "source": [
    "Here is a sanity check. Doing the nested for loops and dot product is the same as using '@', aka matmul, which is also the same result as sklearn. The three cells below are equal. I will be going forward with '@' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f54b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2258, 2.1549, 1.8836, ..., 2.224 , 2.3089, 1.4967],\n",
       "       [2.1549, 2.1061, 1.7873, ..., 2.1159, 2.1993, 1.4239],\n",
       "       [1.8836, 1.7873, 1.7736, ..., 2.0285, 2.1597, 1.3861],\n",
       "       ...,\n",
       "       [2.224 , 2.1159, 2.0285, ..., 2.3671, 2.4829, 1.6044],\n",
       "       [2.3089, 2.1993, 2.1597, ..., 2.4829, 2.6862, 1.632 ],\n",
       "       [1.4967, 1.4239, 1.3861, ..., 1.6044, 1.632 , 1.1844]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1,_ = x_train.shape\n",
    "m2,_ = x_train.shape\n",
    "K = np.zeros((m1, m2))\n",
    "for i in range(m1):\n",
    "    for j in range(m2):\n",
    "        K[i,j] = (np.dot(x_train[i,:], x_train[j,:]))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e120d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2258, 2.1549, 1.8836, ..., 2.224 , 2.3089, 1.4967],\n",
       "       [2.1549, 2.1061, 1.7873, ..., 2.1159, 2.1993, 1.4239],\n",
       "       [1.8836, 1.7873, 1.7736, ..., 2.0285, 2.1597, 1.3861],\n",
       "       ...,\n",
       "       [2.224 , 2.1159, 2.0285, ..., 2.3671, 2.4829, 1.6044],\n",
       "       [2.3089, 2.1993, 2.1597, ..., 2.4829, 2.6862, 1.632 ],\n",
       "       [1.4967, 1.4239, 1.3861, ..., 1.6044, 1.632 , 1.1844]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklean implementaion\n",
    "linear_kernel(x_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a3ec11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2258, 2.1549, 1.8836, ..., 2.224 , 2.3089, 1.4967],\n",
       "       [2.1549, 2.1061, 1.7873, ..., 2.1159, 2.1993, 1.4239],\n",
       "       [1.8836, 1.7873, 1.7736, ..., 2.0285, 2.1597, 1.3861],\n",
       "       ...,\n",
       "       [2.224 , 2.1159, 2.0285, ..., 2.3671, 2.4829, 1.6044],\n",
       "       [2.3089, 2.1993, 2.1597, ..., 2.4829, 2.6862, 1.632 ],\n",
       "       [1.4967, 1.4239, 1.3861, ..., 1.6044, 1.632 , 1.1844]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the easiest\n",
    "x_train_lk = (x_train@x_train.T)\n",
    "x_train_lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be261a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 268)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_lk = (x_test@x_train.T)\n",
    "x_test_lk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ecaea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_259</th>\n",
       "      <th>Weight_260</th>\n",
       "      <th>Weight_261</th>\n",
       "      <th>Weight_262</th>\n",
       "      <th>Weight_263</th>\n",
       "      <th>Weight_264</th>\n",
       "      <th>Weight_265</th>\n",
       "      <th>Weight_266</th>\n",
       "      <th>Weight_267</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029816</td>\n",
       "      <td>0.031341</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.074498</td>\n",
       "      <td>0.032969</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.045377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.041545</td>\n",
       "      <td>0.032067</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.034011</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0.035511</td>\n",
       "      <td>-19.493451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.128826</td>\n",
       "      <td>-0.095660</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>-0.031667</td>\n",
       "      <td>-0.140254</td>\n",
       "      <td>-0.074763</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>-0.112745</td>\n",
       "      <td>-0.084766</td>\n",
       "      <td>0.083664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110066</td>\n",
       "      <td>0.054653</td>\n",
       "      <td>0.071271</td>\n",
       "      <td>-0.024115</td>\n",
       "      <td>-0.066290</td>\n",
       "      <td>-0.027101</td>\n",
       "      <td>-0.075397</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>-0.097745</td>\n",
       "      <td>19.601696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.325591</td>\n",
       "      <td>-2.298186</td>\n",
       "      <td>-1.547406</td>\n",
       "      <td>-2.027124</td>\n",
       "      <td>-1.505314</td>\n",
       "      <td>-1.079832</td>\n",
       "      <td>-2.110807</td>\n",
       "      <td>-1.858849</td>\n",
       "      <td>-2.388795</td>\n",
       "      <td>-2.091542</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.363291</td>\n",
       "      <td>-1.101895</td>\n",
       "      <td>-2.233211</td>\n",
       "      <td>-1.326405</td>\n",
       "      <td>-2.104018</td>\n",
       "      <td>-1.569929</td>\n",
       "      <td>-2.004983</td>\n",
       "      <td>-2.020710</td>\n",
       "      <td>-1.116802</td>\n",
       "      <td>881.333004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.852687</td>\n",
       "      <td>-1.614870</td>\n",
       "      <td>2.031921</td>\n",
       "      <td>-1.340171</td>\n",
       "      <td>0.350807</td>\n",
       "      <td>0.815637</td>\n",
       "      <td>2.861968</td>\n",
       "      <td>0.588308</td>\n",
       "      <td>-1.113975</td>\n",
       "      <td>2.036954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194748</td>\n",
       "      <td>-0.121520</td>\n",
       "      <td>1.673075</td>\n",
       "      <td>0.370304</td>\n",
       "      <td>-1.189052</td>\n",
       "      <td>-0.095279</td>\n",
       "      <td>1.509874</td>\n",
       "      <td>2.306719</td>\n",
       "      <td>0.908610</td>\n",
       "      <td>-339.834706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029030</td>\n",
       "      <td>0.045244</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>0.203149</td>\n",
       "      <td>0.095817</td>\n",
       "      <td>0.210922</td>\n",
       "      <td>0.623288</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.158640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133733</td>\n",
       "      <td>0.381164</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.211067</td>\n",
       "      <td>0.112517</td>\n",
       "      <td>0.188817</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.134176</td>\n",
       "      <td>0.191198</td>\n",
       "      <td>-72.285431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.112292</td>\n",
       "      <td>-0.088166</td>\n",
       "      <td>1.268413</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.064405</td>\n",
       "      <td>0.415518</td>\n",
       "      <td>2.050423</td>\n",
       "      <td>0.497145</td>\n",
       "      <td>0.269832</td>\n",
       "      <td>1.922934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.481926</td>\n",
       "      <td>1.841427</td>\n",
       "      <td>0.634497</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>0.501776</td>\n",
       "      <td>0.978662</td>\n",
       "      <td>1.787581</td>\n",
       "      <td>0.313826</td>\n",
       "      <td>-373.791961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.424177</td>\n",
       "      <td>-0.123569</td>\n",
       "      <td>-0.169247</td>\n",
       "      <td>1.169128</td>\n",
       "      <td>0.478533</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>-1.023782</td>\n",
       "      <td>-0.288359</td>\n",
       "      <td>-0.846068</td>\n",
       "      <td>-0.182589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472083</td>\n",
       "      <td>1.254460</td>\n",
       "      <td>-0.555692</td>\n",
       "      <td>-0.392064</td>\n",
       "      <td>0.629220</td>\n",
       "      <td>-0.144211</td>\n",
       "      <td>0.091844</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>0.355122</td>\n",
       "      <td>45.004395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.618203</td>\n",
       "      <td>4.143866</td>\n",
       "      <td>-1.761363</td>\n",
       "      <td>2.028084</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>-0.360913</td>\n",
       "      <td>-2.494228</td>\n",
       "      <td>1.101533</td>\n",
       "      <td>4.119428</td>\n",
       "      <td>-1.973437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.882034</td>\n",
       "      <td>-0.991856</td>\n",
       "      <td>-0.965066</td>\n",
       "      <td>0.485172</td>\n",
       "      <td>2.566852</td>\n",
       "      <td>1.106421</td>\n",
       "      <td>-0.576369</td>\n",
       "      <td>-2.372157</td>\n",
       "      <td>-0.589721</td>\n",
       "      <td>-146.533546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0  0.029816  0.031341  0.040736  0.033559  0.030333  0.038119  0.074498   \n",
       "1 -0.128826 -0.095660 -0.020059 -0.031667 -0.140254 -0.074763  0.018640   \n",
       "2 -2.325591 -2.298186 -1.547406 -2.027124 -1.505314 -1.079832 -2.110807   \n",
       "3 -0.852687 -1.614870  2.031921 -1.340171  0.350807  0.815637  2.861968   \n",
       "4 -0.029030  0.045244  0.157004  0.203149  0.095817  0.210922  0.623288   \n",
       "5  0.112292 -0.088166  1.268413 -0.034959  0.064405  0.415518  2.050423   \n",
       "6 -0.424177 -0.123569 -0.169247  1.169128  0.478533  0.035312 -1.023782   \n",
       "7  3.618203  4.143866 -1.761363  2.028084  0.625673 -0.360913 -2.494228   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_259  Weight_260  Weight_261  \\\n",
       "0  0.032969  0.033898  0.045377  ...    0.035622    0.043069    0.044931   \n",
       "1 -0.112745 -0.084766  0.083664  ...   -0.110066    0.054653    0.071271   \n",
       "2 -1.858849 -2.388795 -2.091542  ...   -1.363291   -1.101895   -2.233211   \n",
       "3  0.588308 -1.113975  2.036954  ...   -0.194748   -0.121520    1.673075   \n",
       "4  0.039999  0.010446  0.158640  ...    0.133733    0.381164    0.123264   \n",
       "5  0.497145  0.269832  1.922934  ...    0.088798    0.481926    1.841427   \n",
       "6 -0.288359 -0.846068 -0.182589  ...   -0.472083    1.254460   -0.555692   \n",
       "7  1.101533  4.119428 -1.973437  ...    1.882034   -0.991856   -0.965066   \n",
       "\n",
       "   Weight_262  Weight_263  Weight_264  Weight_265  Weight_266  Weight_267  \\\n",
       "0    0.041545    0.032067    0.039507    0.034011    0.042333    0.035511   \n",
       "1   -0.024115   -0.066290   -0.027101   -0.075397    0.044607   -0.097745   \n",
       "2   -1.326405   -2.104018   -1.569929   -2.004983   -2.020710   -1.116802   \n",
       "3    0.370304   -1.189052   -0.095279    1.509874    2.306719    0.908610   \n",
       "4    0.211067    0.112517    0.188817    0.042357    0.134176    0.191198   \n",
       "5    0.634497    0.018704    0.501776    0.978662    1.787581    0.313826   \n",
       "6   -0.392064    0.629220   -0.144211    0.091844    0.077451    0.355122   \n",
       "7    0.485172    2.566852    1.106421   -0.576369   -2.372157   -0.589721   \n",
       "\n",
       "         Bias  \n",
       "0  -19.493451  \n",
       "1   19.601696  \n",
       "2  881.333004  \n",
       "3 -339.834706  \n",
       "4  -72.285431  \n",
       "5 -373.791961  \n",
       "6   45.004395  \n",
       "7 -146.533546  \n",
       "\n",
       "[8 rows x 269 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearKernelSVM = getSVMs(x_train_lk, y_train)\n",
    "linearKernelSVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31bb3202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Overall accuracy: ', 0.75)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getAccuracy(x_test_lk, y_test, SVM = linearKernelSVM )\n",
    "\"Overall accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3576603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  0  or  L  :  0.0\n",
      "Accuracy for  1  or  S  :  0.0\n",
      "Accuracy for  2  or  cp  :  1.0\n",
      "Accuracy for  3  or  im  :  0.6666666666666666\n",
      "Accuracy for  4  or  mL  :  0.0\n",
      "Accuracy for  5  or  mU  :  0.0\n",
      "Accuracy for  6  or  om  :  0.0\n",
      "Accuracy for  7  or  pp  :  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "getAccuracyPerNumber(x_test_lk, y_test, SVM = linearKernelSVM )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f07272",
   "metadata": {},
   "source": [
    "### Polynomial Kernel OneVsAll SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94620bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.40578564,  9.95339401,  8.31514896, ..., 10.394176  ,\n",
       "        10.94881921,  6.23351089],\n",
       "       [ 9.95339401,  9.64785721,  7.76904129, ...,  9.70883281,\n",
       "        10.23552049,  5.87529121],\n",
       "       [ 8.31514896,  7.76904129,  7.69285696, ...,  9.17181225,\n",
       "         9.98370409,  5.69347321],\n",
       "       ...,\n",
       "       [10.394176  ,  9.70883281,  9.17181225, ..., 11.33736241,\n",
       "        12.13059241,  6.78289936],\n",
       "       [10.94881921, 10.23552049,  9.98370409, ..., 12.13059241,\n",
       "        13.58807044,  6.927424  ],\n",
       "       [ 6.23351089,  5.87529121,  5.69347321, ...,  6.78289936,\n",
       "         6.927424  ,  4.77160336]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pk = (x_train@x_train.T + 1) ** 2\n",
    "x_train_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d421f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.40578564,  9.95339401,  8.31514896, ..., 10.394176  ,\n",
       "        10.94881921,  6.23351089],\n",
       "       [ 9.95339401,  9.64785721,  7.76904129, ...,  9.70883281,\n",
       "        10.23552049,  5.87529121],\n",
       "       [ 8.31514896,  7.76904129,  7.69285696, ...,  9.17181225,\n",
       "         9.98370409,  5.69347321],\n",
       "       ...,\n",
       "       [10.394176  ,  9.70883281,  9.17181225, ..., 11.33736241,\n",
       "        12.13059241,  6.78289936],\n",
       "       [10.94881921, 10.23552049,  9.98370409, ..., 12.13059241,\n",
       "        13.58807044,  6.927424  ],\n",
       "       [ 6.23351089,  5.87529121,  5.69347321, ...,  6.78289936,\n",
       "         6.927424  ,  4.77160336]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "polynomial_kernel(x_train, x_train, coef0 = 1,degree = 2, gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aeaaf857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 268)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pk = (x_test@x_train.T + 1) ** 2\n",
    "x_test_pk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae54b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_259</th>\n",
       "      <th>Weight_260</th>\n",
       "      <th>Weight_261</th>\n",
       "      <th>Weight_262</th>\n",
       "      <th>Weight_263</th>\n",
       "      <th>Weight_264</th>\n",
       "      <th>Weight_265</th>\n",
       "      <th>Weight_266</th>\n",
       "      <th>Weight_267</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.013938</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>-13.824352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023621</td>\n",
       "      <td>-0.017087</td>\n",
       "      <td>-0.004547</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>-0.021920</td>\n",
       "      <td>-0.010647</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.019562</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015720</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>-0.004101</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>-0.004748</td>\n",
       "      <td>-0.014880</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>-0.014056</td>\n",
       "      <td>15.978626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.416950</td>\n",
       "      <td>-0.402582</td>\n",
       "      <td>-0.253623</td>\n",
       "      <td>-0.348199</td>\n",
       "      <td>-0.236895</td>\n",
       "      <td>-0.151190</td>\n",
       "      <td>-0.424119</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>-0.423700</td>\n",
       "      <td>-0.389532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195676</td>\n",
       "      <td>-0.157768</td>\n",
       "      <td>-0.419470</td>\n",
       "      <td>-0.193139</td>\n",
       "      <td>-0.366234</td>\n",
       "      <td>-0.242053</td>\n",
       "      <td>-0.363583</td>\n",
       "      <td>-0.376329</td>\n",
       "      <td>-0.160401</td>\n",
       "      <td>688.493775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.159119</td>\n",
       "      <td>-0.271945</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>-0.221829</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.090878</td>\n",
       "      <td>0.490914</td>\n",
       "      <td>0.070131</td>\n",
       "      <td>-0.200211</td>\n",
       "      <td>0.314265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035489</td>\n",
       "      <td>-0.026978</td>\n",
       "      <td>0.254283</td>\n",
       "      <td>0.033847</td>\n",
       "      <td>-0.203196</td>\n",
       "      <td>-0.028990</td>\n",
       "      <td>0.223788</td>\n",
       "      <td>0.361466</td>\n",
       "      <td>0.105949</td>\n",
       "      <td>-224.619765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004263</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.024554</td>\n",
       "      <td>0.033053</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>0.120441</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.028506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.051007</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.028652</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>-51.248862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013673</td>\n",
       "      <td>-0.015428</td>\n",
       "      <td>0.171149</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.045628</td>\n",
       "      <td>0.346046</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.302391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.054846</td>\n",
       "      <td>0.292425</td>\n",
       "      <td>0.074199</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.061801</td>\n",
       "      <td>0.145269</td>\n",
       "      <td>0.279373</td>\n",
       "      <td>0.034917</td>\n",
       "      <td>-253.385481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.070384</td>\n",
       "      <td>-0.019263</td>\n",
       "      <td>-0.024850</td>\n",
       "      <td>0.191273</td>\n",
       "      <td>0.069667</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>-0.187206</td>\n",
       "      <td>-0.044716</td>\n",
       "      <td>-0.139000</td>\n",
       "      <td>-0.029472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061981</td>\n",
       "      <td>0.166707</td>\n",
       "      <td>-0.094902</td>\n",
       "      <td>-0.051840</td>\n",
       "      <td>0.104079</td>\n",
       "      <td>-0.020110</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>42.392377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.655830</td>\n",
       "      <td>0.713557</td>\n",
       "      <td>-0.199691</td>\n",
       "      <td>0.353259</td>\n",
       "      <td>0.127015</td>\n",
       "      <td>-0.011356</td>\n",
       "      <td>-0.361395</td>\n",
       "      <td>0.228815</td>\n",
       "      <td>0.734036</td>\n",
       "      <td>-0.247458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277612</td>\n",
       "      <td>-0.100768</td>\n",
       "      <td>-0.073980</td>\n",
       "      <td>0.106847</td>\n",
       "      <td>0.453206</td>\n",
       "      <td>0.201242</td>\n",
       "      <td>-0.020567</td>\n",
       "      <td>-0.317494</td>\n",
       "      <td>-0.043166</td>\n",
       "      <td>-209.786318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0  0.004834  0.005039  0.005986  0.005297  0.004272  0.004829  0.013938   \n",
       "1 -0.023621 -0.017087 -0.004547 -0.005689 -0.021920 -0.010647  0.001381   \n",
       "2 -0.416950 -0.402582 -0.253623 -0.348199 -0.236895 -0.151190 -0.424119   \n",
       "3 -0.159119 -0.271945  0.281023 -0.221829  0.037008  0.090878  0.490914   \n",
       "4 -0.004263  0.007710  0.024554  0.033053  0.014552  0.027467  0.120441   \n",
       "5  0.013673 -0.015428  0.171149 -0.007165  0.006301  0.045628  0.346046   \n",
       "6 -0.070384 -0.019263 -0.024850  0.191273  0.069667  0.004393 -0.187206   \n",
       "7  0.655830  0.713557 -0.199691  0.353259  0.127015 -0.011356 -0.361395   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_259  Weight_260  Weight_261  \\\n",
       "0  0.004978  0.005503  0.007628  ...    0.004672    0.005670    0.007641   \n",
       "1 -0.019562 -0.015748  0.013672  ...   -0.015720    0.007285    0.011544   \n",
       "2 -0.313249 -0.423700 -0.389532  ...   -0.195676   -0.157768   -0.419470   \n",
       "3  0.070131 -0.200211  0.314265  ...   -0.035489   -0.026978    0.254283   \n",
       "4  0.006940  0.002037  0.028506  ...    0.017913    0.051007    0.022459   \n",
       "5  0.066663  0.037082  0.302391  ...    0.008669    0.054846    0.292425   \n",
       "6 -0.044716 -0.139000 -0.029472  ...   -0.061981    0.166707   -0.094902   \n",
       "7  0.228815  0.734036 -0.247458  ...    0.277612   -0.100768   -0.073980   \n",
       "\n",
       "   Weight_262  Weight_263  Weight_264  Weight_265  Weight_266  Weight_267  \\\n",
       "0    0.005535    0.005094    0.005575    0.005472    0.007058    0.004584   \n",
       "1   -0.004101   -0.011885   -0.004748   -0.014880    0.006353   -0.014056   \n",
       "2   -0.193139   -0.366234   -0.242053   -0.363583   -0.376329   -0.160401   \n",
       "3    0.033847   -0.203196   -0.028990    0.223788    0.361466    0.105949   \n",
       "4    0.028652    0.018709    0.027283    0.008252    0.024390    0.025677   \n",
       "5    0.074199    0.000226    0.061801    0.145269    0.279373    0.034917   \n",
       "6   -0.051840    0.104079   -0.020110    0.016249    0.015183    0.046496   \n",
       "7    0.106847    0.453206    0.201242   -0.020567   -0.317494   -0.043166   \n",
       "\n",
       "         Bias  \n",
       "0  -13.824352  \n",
       "1   15.978626  \n",
       "2  688.493775  \n",
       "3 -224.619765  \n",
       "4  -51.248862  \n",
       "5 -253.385481  \n",
       "6   42.392377  \n",
       "7 -209.786318  \n",
       "\n",
       "[8 rows x 269 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyKernelSVM = getSVMs(x_train_pk, y_train)\n",
    "polyKernelSVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcfe688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Overall accuracy: ', 0.75)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getAccuracy(x_test_pk, y_test, SVM = polyKernelSVM)\n",
    "\"Overall accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96f763d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  0  or  L  :  0.0\n",
      "Accuracy for  1  or  S  :  0.0\n",
      "Accuracy for  2  or  cp  :  1.0\n",
      "Accuracy for  3  or  im  :  0.6666666666666666\n",
      "Accuracy for  4  or  mL  :  0.0\n",
      "Accuracy for  5  or  mU  :  0.0\n",
      "Accuracy for  6  or  om  :  0.0\n",
      "Accuracy for  7  or  pp  :  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "getAccuracyPerNumber(x_test_pk, y_test, SVM = polyKernelSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beca60a",
   "metadata": {},
   "source": [
    "### RBF Kernel OneVsAll SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a371816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 268)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change x_TRAIN into the kernel form\n",
    "gamma = 5\n",
    "m1 = x_train.shape[0]\n",
    "m2 = x_train.shape[0]\n",
    "K = np.zeros((m1, m2))  \n",
    "for i in range(m1):\n",
    "    for j in range(m2):\n",
    "        K[i,j] = np.exp( - gamma * np.linalg.norm(x_train[i,:] - x_train[j,:])**2 )\n",
    "x_train_g = K \n",
    "x_train_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56703c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 268)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change x_TEST into the kernel form\n",
    "m1 = x_test.shape[0]\n",
    "m2 = x_train.shape[0]\n",
    "K = np.zeros((m1, m2))  \n",
    "for i in range(m1):\n",
    "    for j in range(m2):\n",
    "        K[i,j] = np.exp( -gamma * np.linalg.norm(x_test[i,:] - x_train[j,:])**2 )\n",
    "x_test_g = K \n",
    "x_test_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3b6f04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_259</th>\n",
       "      <th>Weight_260</th>\n",
       "      <th>Weight_261</th>\n",
       "      <th>Weight_262</th>\n",
       "      <th>Weight_263</th>\n",
       "      <th>Weight_264</th>\n",
       "      <th>Weight_265</th>\n",
       "      <th>Weight_266</th>\n",
       "      <th>Weight_267</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.092350</td>\n",
       "      <td>-0.027322</td>\n",
       "      <td>-0.057581</td>\n",
       "      <td>-0.029807</td>\n",
       "      <td>-0.012262</td>\n",
       "      <td>0.051829</td>\n",
       "      <td>-0.069209</td>\n",
       "      <td>-0.081645</td>\n",
       "      <td>-0.009872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023576</td>\n",
       "      <td>-0.010042</td>\n",
       "      <td>-0.011961</td>\n",
       "      <td>-0.022334</td>\n",
       "      <td>-0.079101</td>\n",
       "      <td>-0.042691</td>\n",
       "      <td>-0.045777</td>\n",
       "      <td>-0.013807</td>\n",
       "      <td>-0.012573</td>\n",
       "      <td>1.827474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.227459</td>\n",
       "      <td>-0.152850</td>\n",
       "      <td>-0.008310</td>\n",
       "      <td>-0.014010</td>\n",
       "      <td>-0.069576</td>\n",
       "      <td>-0.018224</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>-0.142911</td>\n",
       "      <td>-0.130679</td>\n",
       "      <td>0.073483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046448</td>\n",
       "      <td>0.030229</td>\n",
       "      <td>0.066294</td>\n",
       "      <td>-0.008841</td>\n",
       "      <td>-0.090179</td>\n",
       "      <td>-0.017816</td>\n",
       "      <td>-0.067931</td>\n",
       "      <td>0.047155</td>\n",
       "      <td>-0.023147</td>\n",
       "      <td>1.008084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.606170</td>\n",
       "      <td>-3.815017</td>\n",
       "      <td>1.224969</td>\n",
       "      <td>-1.362157</td>\n",
       "      <td>1.652092</td>\n",
       "      <td>3.377806</td>\n",
       "      <td>-0.139220</td>\n",
       "      <td>-0.917722</td>\n",
       "      <td>-3.781187</td>\n",
       "      <td>-0.633320</td>\n",
       "      <td>...</td>\n",
       "      <td>2.667629</td>\n",
       "      <td>2.945758</td>\n",
       "      <td>-0.885892</td>\n",
       "      <td>2.841779</td>\n",
       "      <td>-2.454242</td>\n",
       "      <td>1.825746</td>\n",
       "      <td>-1.390003</td>\n",
       "      <td>-0.633337</td>\n",
       "      <td>3.059048</td>\n",
       "      <td>-45.821309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.704025</td>\n",
       "      <td>-2.720102</td>\n",
       "      <td>0.544612</td>\n",
       "      <td>-1.627132</td>\n",
       "      <td>-0.434572</td>\n",
       "      <td>-0.050359</td>\n",
       "      <td>0.385037</td>\n",
       "      <td>-1.031915</td>\n",
       "      <td>-2.237631</td>\n",
       "      <td>0.771766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463443</td>\n",
       "      <td>-0.196975</td>\n",
       "      <td>0.584650</td>\n",
       "      <td>-0.349531</td>\n",
       "      <td>-2.186835</td>\n",
       "      <td>-0.924014</td>\n",
       "      <td>0.187455</td>\n",
       "      <td>0.972225</td>\n",
       "      <td>-0.024639</td>\n",
       "      <td>28.860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.299173</td>\n",
       "      <td>-0.257952</td>\n",
       "      <td>-0.075215</td>\n",
       "      <td>-0.133496</td>\n",
       "      <td>-0.077349</td>\n",
       "      <td>-0.027998</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>-0.194469</td>\n",
       "      <td>-0.236544</td>\n",
       "      <td>-0.047653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061333</td>\n",
       "      <td>-0.011248</td>\n",
       "      <td>-0.056205</td>\n",
       "      <td>-0.053314</td>\n",
       "      <td>-0.207097</td>\n",
       "      <td>-0.104974</td>\n",
       "      <td>-0.134204</td>\n",
       "      <td>-0.055853</td>\n",
       "      <td>-0.029051</td>\n",
       "      <td>6.596430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.333802</td>\n",
       "      <td>-1.309359</td>\n",
       "      <td>0.138252</td>\n",
       "      <td>-0.823313</td>\n",
       "      <td>-0.405615</td>\n",
       "      <td>-0.131105</td>\n",
       "      <td>0.293040</td>\n",
       "      <td>-0.710659</td>\n",
       "      <td>-0.958108</td>\n",
       "      <td>0.956391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301839</td>\n",
       "      <td>-0.110349</td>\n",
       "      <td>0.919359</td>\n",
       "      <td>-0.182641</td>\n",
       "      <td>-1.095606</td>\n",
       "      <td>-0.445006</td>\n",
       "      <td>-0.053855</td>\n",
       "      <td>0.834657</td>\n",
       "      <td>-0.149837</td>\n",
       "      <td>14.922934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.749565</td>\n",
       "      <td>-1.191424</td>\n",
       "      <td>-0.351199</td>\n",
       "      <td>0.847945</td>\n",
       "      <td>0.045767</td>\n",
       "      <td>-0.029922</td>\n",
       "      <td>-0.097058</td>\n",
       "      <td>-1.011908</td>\n",
       "      <td>-1.710756</td>\n",
       "      <td>-0.277898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291936</td>\n",
       "      <td>0.378823</td>\n",
       "      <td>-0.414643</td>\n",
       "      <td>-0.265084</td>\n",
       "      <td>-0.006951</td>\n",
       "      <td>-0.436253</td>\n",
       "      <td>-0.507447</td>\n",
       "      <td>-0.230471</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>22.060349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.023417</td>\n",
       "      <td>9.539053</td>\n",
       "      <td>-1.445785</td>\n",
       "      <td>3.169743</td>\n",
       "      <td>-0.680940</td>\n",
       "      <td>-3.107938</td>\n",
       "      <td>-0.529552</td>\n",
       "      <td>4.078794</td>\n",
       "      <td>9.136550</td>\n",
       "      <td>-0.832898</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.479055</td>\n",
       "      <td>-3.026196</td>\n",
       "      <td>-0.201600</td>\n",
       "      <td>-1.960034</td>\n",
       "      <td>6.120009</td>\n",
       "      <td>0.145008</td>\n",
       "      <td>2.011762</td>\n",
       "      <td>-0.920568</td>\n",
       "      <td>-2.864159</td>\n",
       "      <td>-35.454363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0  -0.103223 -0.092350 -0.027322 -0.057581 -0.029807 -0.012262  0.051829   \n",
       "1  -0.227459 -0.152850 -0.008310 -0.014010 -0.069576 -0.018224  0.008834   \n",
       "2  -4.606170 -3.815017  1.224969 -1.362157  1.652092  3.377806 -0.139220   \n",
       "3  -2.704025 -2.720102  0.544612 -1.627132 -0.434572 -0.050359  0.385037   \n",
       "4  -0.299173 -0.257952 -0.075215 -0.133496 -0.077349 -0.027998  0.027091   \n",
       "5  -1.333802 -1.309359  0.138252 -0.823313 -0.405615 -0.131105  0.293040   \n",
       "6  -1.749565 -1.191424 -0.351199  0.847945  0.045767 -0.029922 -0.097058   \n",
       "7  11.023417  9.539053 -1.445785  3.169743 -0.680940 -3.107938 -0.529552   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_259  Weight_260  Weight_261  \\\n",
       "0 -0.069209 -0.081645 -0.009872  ...   -0.023576   -0.010042   -0.011961   \n",
       "1 -0.142911 -0.130679  0.073483  ...   -0.046448    0.030229    0.066294   \n",
       "2 -0.917722 -3.781187 -0.633320  ...    2.667629    2.945758   -0.885892   \n",
       "3 -1.031915 -2.237631  0.771766  ...   -0.463443   -0.196975    0.584650   \n",
       "4 -0.194469 -0.236544 -0.047653  ...   -0.061333   -0.011248   -0.056205   \n",
       "5 -0.710659 -0.958108  0.956391  ...   -0.301839   -0.110349    0.919359   \n",
       "6 -1.011908 -1.710756 -0.277898  ...   -0.291936    0.378823   -0.414643   \n",
       "7  4.078794  9.136550 -0.832898  ...   -1.479055   -3.026196   -0.201600   \n",
       "\n",
       "   Weight_262  Weight_263  Weight_264  Weight_265  Weight_266  Weight_267  \\\n",
       "0   -0.022334   -0.079101   -0.042691   -0.045777   -0.013807   -0.012573   \n",
       "1   -0.008841   -0.090179   -0.017816   -0.067931    0.047155   -0.023147   \n",
       "2    2.841779   -2.454242    1.825746   -1.390003   -0.633337    3.059048   \n",
       "3   -0.349531   -2.186835   -0.924014    0.187455    0.972225   -0.024639   \n",
       "4   -0.053314   -0.207097   -0.104974   -0.134204   -0.055853   -0.029051   \n",
       "5   -0.182641   -1.095606   -0.445006   -0.053855    0.834657   -0.149837   \n",
       "6   -0.265084   -0.006951   -0.436253   -0.507447   -0.230471    0.044358   \n",
       "7   -1.960034    6.120009    0.145008    2.011762   -0.920568   -2.864159   \n",
       "\n",
       "        Bias  \n",
       "0   1.827474  \n",
       "1   1.008084  \n",
       "2 -45.821309  \n",
       "3  28.860400  \n",
       "4   6.596430  \n",
       "5  14.922934  \n",
       "6  22.060349  \n",
       "7 -35.454363  \n",
       "\n",
       "[8 rows x 269 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussSVM = getSVMs(x_train_g, y_train)\n",
    "gaussSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b79b22d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Overall accuracy: ', 0.7941176470588235)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getAccuracy(x_test_g, y_test, SVM = gaussSVM)\n",
    "\"Overall accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22aa7b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  0  or  L  :  0.0\n",
      "Accuracy for  1  or  S  :  0.0\n",
      "Accuracy for  2  or  cp  :  1.0\n",
      "Accuracy for  3  or  im  :  0.7222222222222222\n",
      "Accuracy for  4  or  mL  :  0.0\n",
      "Accuracy for  5  or  mU  :  0.0\n",
      "Accuracy for  6  or  om  :  0.0\n",
      "Accuracy for  7  or  pp  :  1.0\n"
     ]
    }
   ],
   "source": [
    "getAccuracyPerNumber(x_test_g, y_test, SVM = gaussSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f375c79",
   "metadata": {},
   "source": [
    "# Binary SVM's, classifying 2 ('cp') and  3 ('im')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e7e86",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78c08972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakDataSetBinary(x,y, classNeg, classPos):\n",
    "    y_copy = y[(y == classNeg) | (y == classPos)]\n",
    "    x_copy = x[(y == classNeg) | (y == classPos)]\n",
    "    \n",
    "    y_copy[y_copy == classNeg] = -1\n",
    "    y_copy[y_copy ==classPos] = 1\n",
    "    \n",
    "    return x_copy,y_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "786d87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the svm weights and biases\n",
    "def getSVMBinary(x_train, y_train): \n",
    "    \n",
    "    n_columns = x_train.shape[1] + 1\n",
    "    column_names = [f'Weight_{i}' for i in range(n_columns)]\n",
    "    df = pd.DataFrame(0, index=range(1), columns=column_names)\n",
    "    df = df.rename(columns={column_names[-1]: 'Bias'})\n",
    "    \n",
    "    ydual_train  = y_train.copy()\n",
    "    xdual_train = x_train.copy()\n",
    "\n",
    "    N = len(ydual_train)\n",
    "    XPY = xdual_train.copy()\n",
    "    for i in range(N):\n",
    "        if ydual_train[i]==-1:\n",
    "            XPY[i,:] =-1 * xdual_train[i,:]    \n",
    "    A = np.matmul(XPY,XPY.transpose())\n",
    "    AT = A.copy().transpose()\n",
    "    YM = np.outer(ydual_train[1:],ydual_train[1:])\n",
    "    AY = np.outer(A[0,1:],ydual_train[1:])\n",
    "    YA = np.outer(ydual_train[1:],A[0,1:])\n",
    "    Y0S = ydual_train[0]**2\n",
    "    M = AT[1:,1:] + A[0,0]*YM/Y0S - AY/ydual_train[0] - YA/ydual_train[0]\n",
    "    b = np.zeros(N-1)\n",
    "    b = 1 - ydual_train[1:]/ydual_train[0]\n",
    "    aw = np.zeros(N)\n",
    "    for i in range(2,N):\n",
    "        aw[i] = (1-ydual_train[i]/ydual_train[0])/(A[i,i] + A[0,0]*ydual_train[i]**2/ydual_train[0]**2 \n",
    "                                                   - 2*A[0,i]*ydual_train[i]/ydual_train[0])\n",
    "    aw[0] = -sum(ydual_train[1:]*aw[1:])/ydual_train[0]\n",
    "    YA   = ydual_train*aw\n",
    "\n",
    "    wght = sum(xdual_train * YA[:,None])\n",
    "    b =sum(ydual_train - np.matmul(xdual_train,wght))/N\n",
    "    \n",
    "    df.iloc[0,0:-1] = wght\n",
    "    df.iloc[0,-1] = b\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9096d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryAccuracy(x_test, y_test, SVM):\n",
    "    testSetAcc = []\n",
    "    for j in range(x_test.shape[0]):\n",
    "        pred = (SVM.iloc[0,:-1].values@x_test[j]) + SVM.iloc[0,-1] \n",
    "        \n",
    "        testSetAcc.append(np.sign([pred]) == y_test[j])\n",
    "    \n",
    "    return sum(testSetAcc)/len(testSetAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a24d4117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 7), (220,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make new x and y for whatever 2-class dataset we want\n",
    "binX, binY = breakDataSetBinary(x,y, 2, 3)\n",
    "binX.shape, binY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f047391",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bin, x_test_bin, y_train_bin, y_test_bin = train_test_split(binX, binY, train_size = .8,shuffle = True, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e807a52",
   "metadata": {},
   "source": [
    "### Sklearn Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "540d54b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Linear SVM Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM\n",
    "linearSVC = LinearSVC(dual=\"auto\")\n",
    "linearSVC.fit(x_train_bin,y_train_bin)\n",
    "y_pred = linearSVC.predict(x_test_bin)\n",
    "\"sklean Linear SVM Accuracy: \" , accuracy_score(y_pred,y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d181cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Linear Kernel SVM Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Kernel SVM\n",
    "linearKernelSVC = SVC(kernel = \"linear\")\n",
    "linearKernelSVC.fit(x_train_bin,y_train_bin)\n",
    "y_pred = linearKernelSVC.predict(x_test_bin)\n",
    "\"sklean Linear Kernel SVM Accuracy: \" , accuracy_score(y_pred,y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "516a70eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean Polynomial SVM Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Polynomial Kernel SVM\n",
    "polySVC = SVC(kernel = \"poly\")\n",
    "polySVC.fit(x_train_bin,y_train_bin)\n",
    "y_pred = polySVC.predict(x_test_bin)\n",
    "\"sklean Polynomial SVM Accuracy: \" , accuracy_score(y_pred,y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a966a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklean RBF SVM Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RBF Kernel SVM\n",
    "rbfSVC = SVC(kernel = \"rbf\")\n",
    "rbfSVC.fit(x_train_bin,y_train_bin)\n",
    "y_pred = rbfSVC.predict(x_test_bin)\n",
    "\"sklean RBF SVM Accuracy: \" , accuracy_score(y_pred,y_test_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e41a6",
   "metadata": {},
   "source": [
    "### Linear (No Kernel) Binary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7553f117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.44046</td>\n",
       "      <td>8.256893</td>\n",
       "      <td>-2.020606e-14</td>\n",
       "      <td>-4.507505e-14</td>\n",
       "      <td>30.061676</td>\n",
       "      <td>174.304006</td>\n",
       "      <td>152.11576</td>\n",
       "      <td>-226.904196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weight_0  Weight_1      Weight_2      Weight_3   Weight_4    Weight_5  \\\n",
       "0  114.44046  8.256893 -2.020606e-14 -4.507505e-14  30.061676  174.304006   \n",
       "\n",
       "    Weight_6        Bias  \n",
       "0  152.11576 -226.904196  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarySVM = getSVMBinary(x_train_bin, y_train_bin)\n",
    "binarySVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36318b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getBinaryAccuracy(x_test_bin, y_test_bin, binarySVM)[0]\n",
    "\"Accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d6e0e",
   "metadata": {},
   "source": [
    "### Linear Kernel Binary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1ae7266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_binLin = (x_train_bin@x_train_bin.T +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f7202f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_binLin = (x_test_bin@x_train_bin.T +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6339f5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_167</th>\n",
       "      <th>Weight_168</th>\n",
       "      <th>Weight_169</th>\n",
       "      <th>Weight_170</th>\n",
       "      <th>Weight_171</th>\n",
       "      <th>Weight_172</th>\n",
       "      <th>Weight_173</th>\n",
       "      <th>Weight_174</th>\n",
       "      <th>Weight_175</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.776165</td>\n",
       "      <td>1.568457</td>\n",
       "      <td>1.127405</td>\n",
       "      <td>1.184949</td>\n",
       "      <td>1.25222</td>\n",
       "      <td>1.156369</td>\n",
       "      <td>1.512408</td>\n",
       "      <td>1.243416</td>\n",
       "      <td>2.637813</td>\n",
       "      <td>0.976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.310995</td>\n",
       "      <td>2.269961</td>\n",
       "      <td>1.40919</td>\n",
       "      <td>1.086981</td>\n",
       "      <td>1.39031</td>\n",
       "      <td>2.036696</td>\n",
       "      <td>1.216645</td>\n",
       "      <td>2.397667</td>\n",
       "      <td>1.052194</td>\n",
       "      <td>-748.535817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0  2.776165  1.568457  1.127405  1.184949   1.25222  1.156369  1.512408   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_167  Weight_168  Weight_169  \\\n",
       "0  1.243416  2.637813     0.976  ...    1.310995    2.269961     1.40919   \n",
       "\n",
       "   Weight_170  Weight_171  Weight_172  Weight_173  Weight_174  Weight_175  \\\n",
       "0    1.086981     1.39031    2.036696    1.216645    2.397667    1.052194   \n",
       "\n",
       "         Bias  \n",
       "0 -748.535817  \n",
       "\n",
       "[1 rows x 177 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryLinSVM = getSVMBinary(x_train_binLin, y_train_bin)\n",
    "binaryLinSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eaafc18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy: ', 0.9545454545454546)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getBinaryAccuracy(x_test_binLin, y_test_bin, binaryLinSVM)[0]\n",
    "\"Accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c372929",
   "metadata": {},
   "source": [
    "### Polynomial Kernel Binary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d93f5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_binPoly = (x_train_bin@x_train_bin.T +1 )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5f35a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_binPoly = (x_test_bin@x_train_bin.T +1 )** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "939ca8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_167</th>\n",
       "      <th>Weight_168</th>\n",
       "      <th>Weight_169</th>\n",
       "      <th>Weight_170</th>\n",
       "      <th>Weight_171</th>\n",
       "      <th>Weight_172</th>\n",
       "      <th>Weight_173</th>\n",
       "      <th>Weight_174</th>\n",
       "      <th>Weight_175</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.52576</td>\n",
       "      <td>0.234171</td>\n",
       "      <td>0.152427</td>\n",
       "      <td>0.159653</td>\n",
       "      <td>0.177088</td>\n",
       "      <td>0.159331</td>\n",
       "      <td>0.224659</td>\n",
       "      <td>0.170257</td>\n",
       "      <td>0.494367</td>\n",
       "      <td>0.12192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186919</td>\n",
       "      <td>0.400485</td>\n",
       "      <td>0.202948</td>\n",
       "      <td>0.14208</td>\n",
       "      <td>0.199616</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.166262</td>\n",
       "      <td>0.433306</td>\n",
       "      <td>0.140494</td>\n",
       "      <td>-333.53882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0   0.52576  0.234171  0.152427  0.159653  0.177088  0.159331  0.224659   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_167  Weight_168  Weight_169  \\\n",
       "0  0.170257  0.494367   0.12192  ...    0.186919    0.400485    0.202948   \n",
       "\n",
       "   Weight_170  Weight_171  Weight_172  Weight_173  Weight_174  Weight_175  \\\n",
       "0     0.14208    0.199616      0.3514    0.166262    0.433306    0.140494   \n",
       "\n",
       "        Bias  \n",
       "0 -333.53882  \n",
       "\n",
       "[1 rows x 177 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryPolySVM = getSVMBinary(x_train_binPoly, y_train_bin)\n",
    "binaryPolySVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd836c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy: ', 1.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getBinaryAccuracy(x_test_binPoly, y_test_bin, binaryPolySVM)[0]\n",
    "\"Accuracy: \" , acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fede4d",
   "metadata": {},
   "source": [
    "### RBF Kernel Binary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b45cc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 176)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change x_TRAIN into the kernel form\n",
    "gamma = 1\n",
    "\n",
    "m1 = x_train_bin.shape[0]\n",
    "m2 = x_train_bin.shape[0]\n",
    "K = np.zeros((m1, m2))  \n",
    "for i in range(m1):\n",
    "    for j in range(m2):\n",
    "        K[i,j] = np.exp( -gamma * np.linalg.norm(x_train_bin[i,:] - x_train_bin[j,:])**2 )\n",
    "        \n",
    "x_train_binRBF = K \n",
    "x_train_binRBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99155920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 176)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change x_TEST into the kernel form\n",
    "gamma = 1\n",
    "\n",
    "m1 = x_test_bin.shape[0]\n",
    "m2 = x_train_bin.shape[0]\n",
    "K = np.zeros((m1, m2))  \n",
    "for i in range(m1):\n",
    "    for j in range(m2):\n",
    "        K[i,j] = np.exp( -gamma * np.linalg.norm(x_test_bin[i,:] - x_train_bin[j,:])**2 )\n",
    "        \n",
    "x_test_binRBF = K \n",
    "x_test_binRBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d806d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_167</th>\n",
       "      <th>Weight_168</th>\n",
       "      <th>Weight_169</th>\n",
       "      <th>Weight_170</th>\n",
       "      <th>Weight_171</th>\n",
       "      <th>Weight_172</th>\n",
       "      <th>Weight_173</th>\n",
       "      <th>Weight_174</th>\n",
       "      <th>Weight_175</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.205387</td>\n",
       "      <td>-2.243984</td>\n",
       "      <td>-3.838294</td>\n",
       "      <td>-3.877483</td>\n",
       "      <td>-3.657845</td>\n",
       "      <td>-3.933399</td>\n",
       "      <td>-2.453572</td>\n",
       "      <td>-3.638815</td>\n",
       "      <td>3.42117</td>\n",
       "      <td>-4.347771</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.369824</td>\n",
       "      <td>1.782538</td>\n",
       "      <td>-2.968907</td>\n",
       "      <td>-4.137613</td>\n",
       "      <td>-3.104279</td>\n",
       "      <td>0.423154</td>\n",
       "      <td>-3.524469</td>\n",
       "      <td>2.413333</td>\n",
       "      <td>-4.1625</td>\n",
       "      <td>253.240474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight_0  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  Weight_6  \\\n",
       "0  4.205387 -2.243984 -3.838294 -3.877483 -3.657845 -3.933399 -2.453572   \n",
       "\n",
       "   Weight_7  Weight_8  Weight_9  ...  Weight_167  Weight_168  Weight_169  \\\n",
       "0 -3.638815   3.42117 -4.347771  ...   -3.369824    1.782538   -2.968907   \n",
       "\n",
       "   Weight_170  Weight_171  Weight_172  Weight_173  Weight_174  Weight_175  \\\n",
       "0   -4.137613   -3.104279    0.423154   -3.524469    2.413333     -4.1625   \n",
       "\n",
       "         Bias  \n",
       "0  253.240474  \n",
       "\n",
       "[1 rows x 177 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryRBFSVM = getSVMBinary(x_train_binRBF, y_train_bin)\n",
    "binaryRBFSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cda00859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy: ', 0.9772727272727273)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = getBinaryAccuracy(x_test_binRBF, y_test_bin, binaryRBFSVM)[0]\n",
    "\"Accuracy: \" , acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
